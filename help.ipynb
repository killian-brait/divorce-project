{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help Needed: Why is there no feature importance in the divorce dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test to Try and Fix Feature Importance issues\n",
    "\n",
    "\n",
    "#### Initialize the Dataframe and Process the Data - Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the summary statistics for the features:\n",
      "               Age        Fare    Pclass_1    Pclass_2    Pclass_3  Sex_female  \\\n",
      "count  712.000000  712.000000  712.000000  712.000000  712.000000  712.000000   \n",
      "mean    29.642093   34.567251    0.258427    0.242978    0.498596    0.363764   \n",
      "std     14.492933   52.938648    0.438078    0.429183    0.500350    0.481420   \n",
      "min      0.420000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     20.000000    8.050000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%     28.000000   15.645850    0.000000    0.000000    0.000000    0.000000   \n",
      "75%     38.000000   33.000000    1.000000    0.000000    1.000000    1.000000   \n",
      "max     80.000000  512.329200    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "         Sex_male     SibSp_0     SibSp_1     SibSp_2  ...  Embarked_S  \\\n",
      "count  712.000000  712.000000  712.000000  712.000000  ...  712.000000   \n",
      "mean     0.636236    0.658708    0.257022    0.035112  ...    0.778090   \n",
      "std      0.481420    0.474477    0.437299    0.184193  ...    0.415823   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000  ...    1.000000   \n",
      "50%      1.000000    1.000000    0.000000    0.000000  ...    1.000000   \n",
      "75%      1.000000    1.000000    1.000000    0.000000  ...    1.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
      "\n",
      "       CabinLetter_?  CabinLetter_A  CabinLetter_B  CabinLetter_C  \\\n",
      "count     712.000000     712.000000     712.000000     712.000000   \n",
      "mean        0.742978       0.016854       0.060393       0.071629   \n",
      "std         0.437299       0.128815       0.238381       0.258054   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         1.000000       0.000000       0.000000       0.000000   \n",
      "75%         1.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "       CabinLetter_D  CabinLetter_E  CabinLetter_F  CabinLetter_G  \\\n",
      "count     712.000000     712.000000     712.000000     712.000000   \n",
      "mean        0.043539       0.042135       0.015449       0.005618   \n",
      "std         0.204211       0.201038       0.123419       0.074795   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "       CabinLetter_T  \n",
      "count     712.000000  \n",
      "mean        0.001404  \n",
      "std         0.037477  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 32 columns]\n",
      "--------------------------------------------------------------------\n",
      "This is the number of rows in the dataset: 712\n",
      "--------------------------------------------------------------------\n",
      "This is the number of unique values in each column:\n",
      " Age               88\n",
      "Fare             219\n",
      "Pclass_1           2\n",
      "Pclass_2           2\n",
      "Pclass_3           2\n",
      "Sex_female         2\n",
      "Sex_male           2\n",
      "SibSp_0            2\n",
      "SibSp_1            2\n",
      "SibSp_2            2\n",
      "SibSp_3            2\n",
      "SibSp_4            2\n",
      "SibSp_5            2\n",
      "Parch_0            2\n",
      "Parch_1            2\n",
      "Parch_2            2\n",
      "Parch_3            2\n",
      "Parch_4            2\n",
      "Parch_5            2\n",
      "Parch_6            2\n",
      "Embarked_C         2\n",
      "Embarked_Q         2\n",
      "Embarked_S         2\n",
      "CabinLetter_?      2\n",
      "CabinLetter_A      2\n",
      "CabinLetter_B      2\n",
      "CabinLetter_C      2\n",
      "CabinLetter_D      2\n",
      "CabinLetter_E      2\n",
      "CabinLetter_F      2\n",
      "CabinLetter_G      2\n",
      "CabinLetter_T      2\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/g6ww72790nq6m2qy7cww_h440000gn/T/ipykernel_5390/1195426193.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  titanic_df['CabinLetter'] = titanic_df['Cabin'].str.slice(0,1)\n"
     ]
    }
   ],
   "source": [
    "# Import titanic data\n",
    "titanic = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Processing features:\n",
    "# 1. Drop columns that are not useful\n",
    "titanic_features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked']\n",
    "titanic_df = titanic[titanic_features]\n",
    "titanic_df['CabinLetter'] = titanic_df['Cabin'].str.slice(0,1)\n",
    "X = titanic_df.drop('Cabin',axis=1)\n",
    "X['CabinLetter'] = X['CabinLetter'].fillna(\"?\")\n",
    "X['Pclass'] = X['Pclass'].astype(str)\n",
    "X['SibSp'] = X['SibSp'].astype(str)\n",
    "X['Parch'] = X['Parch'].astype(str)\n",
    "X = X.dropna()\n",
    "t = titanic.loc[X.index, 'Survived']\n",
    "# 2. Convert categorical features to dummy variables (one-hot encoding with pandas)\n",
    "X = pd.get_dummies(X)\n",
    "# Display summary statistics for the features\n",
    "print(f\"These are the summary statistics for the features:\\n {X.describe()}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"This is the number of rows in the dataset: {len(X)}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"This is the number of unique values in each column:\\n {X.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Dataframe and Process the Data - Divorce Dataset\n",
    "\n",
    "Note: The divorce dataset has no missing values and there are exactly 5 unique values per feature (0, 1, 2, 3, 4) that correspond to the following:<br>\n",
    "- 0 - Never\n",
    "- 1 - Seldom\n",
    "- 2 - Averagely\n",
    "- 3 - Frequently\n",
    "- 4 - Always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the summary statistics for the features:\n",
      "                Q1          Q2          Q3          Q4          Q5          Q6  \\\n",
      "count  170.000000  170.000000  170.000000  170.000000  170.000000  170.000000   \n",
      "mean     1.776471    1.652941    1.764706    1.482353    1.541176    0.747059   \n",
      "std      1.627257    1.468654    1.415444    1.504327    1.632169    0.904046   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      2.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
      "75%      3.000000    3.000000    3.000000    3.000000    3.000000    1.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "\n",
      "               Q7          Q8          Q9         Q10  ...         Q45  \\\n",
      "count  170.000000  170.000000  170.000000  170.000000  ...  170.000000   \n",
      "mean     0.494118    1.452941    1.458824    1.576471  ...    2.458824   \n",
      "std      0.898698    1.546371    1.557976    1.421529  ...    1.499925   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000  ...    1.000000   \n",
      "50%      0.000000    1.000000    1.000000    2.000000  ...    3.000000   \n",
      "75%      1.000000    3.000000    3.000000    3.000000  ...    4.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000  ...    4.000000   \n",
      "\n",
      "              Q46         Q47         Q48         Q49         Q50         Q51  \\\n",
      "count  170.000000  170.000000  170.000000  170.000000  170.000000  170.000000   \n",
      "mean     2.552941    2.270588    2.741176    2.382353    2.429412    2.476471   \n",
      "std      1.371786    1.586841    1.137348    1.511587    1.405090    1.260238   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      2.000000    1.000000    2.000000    1.000000    1.000000    2.000000   \n",
      "50%      3.000000    2.000000    3.000000    3.000000    2.000000    3.000000   \n",
      "75%      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "\n",
      "              Q52         Q53         Q54  \n",
      "count  170.000000  170.000000  170.000000  \n",
      "mean     2.517647    2.241176    2.011765  \n",
      "std      1.476537    1.505634    1.667611  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      1.000000    1.000000    0.000000  \n",
      "50%      3.000000    2.000000    2.000000  \n",
      "75%      4.000000    4.000000    4.000000  \n",
      "max      4.000000    4.000000    4.000000  \n",
      "\n",
      "[8 rows x 54 columns]\n",
      "--------------------------------------------------------------------\n",
      "This is the number of rows in the dataset: 170\n",
      "--------------------------------------------------------------------\n",
      "This is the number of unique values in each column:\n",
      " Q1     5\n",
      "Q2     5\n",
      "Q3     5\n",
      "Q4     5\n",
      "Q5     5\n",
      "Q6     5\n",
      "Q7     5\n",
      "Q8     5\n",
      "Q9     5\n",
      "Q10    5\n",
      "Q11    5\n",
      "Q12    5\n",
      "Q13    5\n",
      "Q14    5\n",
      "Q15    5\n",
      "Q16    5\n",
      "Q17    5\n",
      "Q18    5\n",
      "Q19    5\n",
      "Q20    5\n",
      "Q21    5\n",
      "Q22    5\n",
      "Q23    5\n",
      "Q24    5\n",
      "Q25    5\n",
      "Q26    5\n",
      "Q27    5\n",
      "Q28    5\n",
      "Q29    5\n",
      "Q30    5\n",
      "Q31    5\n",
      "Q32    5\n",
      "Q33    5\n",
      "Q34    5\n",
      "Q35    5\n",
      "Q36    5\n",
      "Q37    5\n",
      "Q38    5\n",
      "Q39    5\n",
      "Q40    5\n",
      "Q41    5\n",
      "Q42    5\n",
      "Q43    5\n",
      "Q44    5\n",
      "Q45    5\n",
      "Q46    5\n",
      "Q47    5\n",
      "Q48    5\n",
      "Q49    5\n",
      "Q50    5\n",
      "Q51    5\n",
      "Q52    5\n",
      "Q53    5\n",
      "Q54    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import divorce data\n",
    "divorce = pd.read_csv('data/divorce_data.csv',sep=';')\n",
    "\n",
    "# Processing features:\n",
    "X = divorce.drop('Divorce',axis=1) # .dropna() - dataset has no missing values\n",
    "t = divorce['Divorce']\n",
    "\n",
    "# Display summary statistics for the features\n",
    "print(f\"These are the summary statistics for the features:\\n {X.describe()}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"This is the number of rows in the dataset: {len(X)}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"This is the number of unique values in each column:\\n {X.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (136, 54)\n",
      "Train y shape: (136,)\n",
      "Train X summary statistics:\n",
      "                Q1          Q2          Q3          Q4          Q5          Q6  \\\n",
      "count  136.000000  136.000000  136.000000  136.000000  136.000000  136.000000   \n",
      "mean     1.794118    1.683824    1.786765    1.507353    1.558824    0.698529   \n",
      "std      1.656045    1.484249    1.431953    1.520216    1.649982    0.863411   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      2.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
      "75%      3.000000    3.000000    3.000000    3.000000    3.000000    1.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "\n",
      "               Q7          Q8          Q9         Q10  ...         Q45  \\\n",
      "count  136.000000  136.000000  136.000000  136.000000  ...  136.000000   \n",
      "mean     0.455882    1.455882    1.470588    1.602941  ...    2.419118   \n",
      "std      0.833268    1.558098    1.582034    1.456934  ...    1.522936   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000  ...    1.000000   \n",
      "50%      0.000000    1.000000    0.500000    2.000000  ...    3.000000   \n",
      "75%      1.000000    3.000000    3.000000    3.000000  ...    4.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000  ...    4.000000   \n",
      "\n",
      "              Q46         Q47         Q48         Q49         Q50         Q51  \\\n",
      "count  136.000000  136.000000  136.000000  136.000000  136.000000  136.000000   \n",
      "mean     2.522059    2.257353    2.816176    2.352941    2.419118    2.500000   \n",
      "std      1.408792    1.591628    1.096812    1.551723    1.437875    1.270754   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000    1.000000    2.000000    1.000000    1.000000    2.000000   \n",
      "50%      3.000000    2.000000    3.000000    3.000000    2.000000    3.000000   \n",
      "75%      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "\n",
      "              Q52         Q53         Q54  \n",
      "count  136.000000  136.000000  136.000000  \n",
      "mean     2.514706    2.242647    2.014706  \n",
      "std      1.495600    1.527507    1.686483  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      1.000000    1.000000    0.000000  \n",
      "50%      3.000000    2.000000    2.000000  \n",
      "75%      4.000000    4.000000    4.000000  \n",
      "max      4.000000    4.000000    4.000000  \n",
      "\n",
      "[8 rows x 54 columns]\n",
      "--------------------------------------------------------------------\n",
      "Test X summary statistics:\n",
      "               Q1         Q2         Q3         Q4         Q5         Q6  \\\n",
      "count  34.000000  34.000000  34.000000  34.000000  34.000000  34.000000   \n",
      "mean    1.705882   1.529412   1.676471   1.382353   1.470588   0.941176   \n",
      "std     1.528109   1.419246   1.364498   1.456744   1.580857   1.042758   \n",
      "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "25%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "50%     2.000000   2.000000   2.000000   1.500000   1.000000   1.000000   \n",
      "75%     3.000000   3.000000   3.000000   2.750000   3.000000   1.000000   \n",
      "max     4.000000   4.000000   4.000000   4.000000   4.000000   4.000000   \n",
      "\n",
      "              Q7         Q8         Q9        Q10  ...        Q45        Q46  \\\n",
      "count  34.000000  34.000000  34.000000  34.000000  ...  34.000000  34.000000   \n",
      "mean    0.647059   1.441176   1.411765   1.470588  ...   2.617647   2.676471   \n",
      "std     1.124988   1.521386   1.479509   1.284766  ...   1.414529   1.224017   \n",
      "min     0.000000   0.000000   0.000000   0.000000  ...   0.000000   0.000000   \n",
      "25%     0.000000   0.000000   0.000000   0.000000  ...   2.000000   2.000000   \n",
      "50%     0.000000   1.000000   1.000000   2.000000  ...   3.000000   3.000000   \n",
      "75%     1.000000   3.000000   3.000000   2.750000  ...   4.000000   4.000000   \n",
      "max     4.000000   4.000000   4.000000   4.000000  ...   4.000000   4.000000   \n",
      "\n",
      "             Q47        Q48        Q49        Q50        Q51        Q52  \\\n",
      "count  34.000000  34.000000  34.000000  34.000000  34.000000  34.000000   \n",
      "mean    2.323529   2.441176   2.500000   2.470588   2.382353   2.529412   \n",
      "std     1.590132   1.259898   1.354006   1.284766   1.231277   1.419246   \n",
      "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "25%     1.000000   2.000000   1.000000   1.250000   1.250000   1.250000   \n",
      "50%     3.000000   2.500000   2.500000   2.500000   2.000000   3.000000   \n",
      "75%     4.000000   3.000000   4.000000   4.000000   3.000000   4.000000   \n",
      "max     4.000000   4.000000   4.000000   4.000000   4.000000   4.000000   \n",
      "\n",
      "             Q53       Q54  \n",
      "count  34.000000  34.00000  \n",
      "mean    2.235294   2.00000  \n",
      "std     1.436722   1.61433  \n",
      "min     0.000000   0.00000  \n",
      "25%     1.000000   0.25000  \n",
      "50%     2.000000   2.00000  \n",
      "75%     3.750000   4.00000  \n",
      "max     4.000000   4.00000  \n",
      "\n",
      "[8 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "# Done with sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, t, test_size=0.2)\n",
    "\n",
    "# Print the train X and y shapes\n",
    "print(f\"Train X shape: {train_X.shape}\")\n",
    "print(f\"Train y shape: {train_y.shape}\")\n",
    "\n",
    "# Print the summary statistics of the training features and testing features\n",
    "print(f\"Train X summary statistics:\\n {train_X.describe()}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"Test X summary statistics:\\n {val_X.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding PCA\n",
    "\n",
    "Here we'll reduce the dimensionality of the feature dataset from 54 down to 20. This may improve the ability to get feature importance from the knn model. Note that this will reduce the ability to understand the reduced features since they will become combinations of varios questions. If one hot encoding were to be used as well, that would reduce the understandibility beyond a point of any knowledge gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "train_X_pca = pca.fit_transform(train_X)\n",
    "val_X_pca = pca.transform(val_X)\n",
    "\n",
    "# Convert it back to DataFrame\n",
    "pca_columns = [f'PCA_feature_{i+1}' for i in range(train_X_pca.shape[1])]\n",
    "train_X_pca_df = pd.DataFrame(train_X_pca, columns=pca_columns)\n",
    "val_X_pca_df = pd.DataFrame(val_X_pca, columns=pca_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Model\n",
    "Here we'll instantiate and train a KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(train_X_pca, train_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn.predict(val_X_pca)\n",
    "original_accuracy = accuracy_score(val_y, knn_pred)\n",
    "print(f\"The prediction accuracy is: {original_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation Feature-Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/killianbrait/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PCA_feature_1    0.488235\n",
       "PCA_feature_2    0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "npermutations = 10\n",
    "feature_names = train_X_pca_df.columns.tolist()\n",
    "importances = {}\n",
    "for col in train_X_pca_df.columns:\n",
    "    importances[col] = 0\n",
    "\n",
    "# Loop through the features and make predictions on permuted data\n",
    "for col in train_X_pca_df.columns:\n",
    "    for perm in range(npermutations):\n",
    "        # Permute the column of the validation data\n",
    "        val_X_perm = val_X_pca_df.copy()\n",
    "        val_X_perm[col] = val_X_pca_df[col].sample(frac=1, replace=False).values # np.random.permutation(val_X_perm[col])\n",
    "        # Make predictions on the new data\n",
    "        preds = knn.predict(val_X_perm)\n",
    "        # Compute the accuracy score\n",
    "        permuted_accuracy = accuracy_score(val_y, preds)\n",
    "\n",
    "        # Calculate feature importance\n",
    "        importances[col] += original_accuracy - permuted_accuracy\n",
    "    \n",
    "    # Normalize importances\n",
    "    importances[col] /= npermutations\n",
    "\n",
    "# Display importances in descending order in a Series\n",
    "feature_importances = pd.Series(importances).sort_values(ascending=False)\n",
    "\n",
    "display(feature_importances.head(35))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
